# Machine Learning Pipeline
This repository will show how to create and deploy a Machine Learning model in Google Cloud Platform using Terraform

## Folder structure
+ application - ml_model: this contains the code to create a machine learning model and save that in SavedModel format. This also contains the python code to test model prediction after its deployed as a service in Google Cloud. 
+ fashion: this folder is automatrically generated by ml_model which contains the tensorflow model in SavedModel format. 
+ infrastructure: this folder containts the code to provision the necessary infrastructure to deploy and serve the ternsorflow model in google cloud platform. 

## Prerequisites
### Mac OS
+ Install Homebrew - package manager
+ Install python 3.10.2 and add this to the PATH
+ Install Terraform 
+ Create a google cloud account and enable billing
+ Install Google Cloud SDK and initialize, authorize 
+ Install Kubernetes CLI

## Steps
1. Clone/Fork this repository 
2. cd into the project_directory [mlPipeline]
3. Run `cd application/ml_model`
4. Run `pip install -r requirements.txt`
5. Run `python -u ml_model.py`
6. Run `cd ../../ && cd infrastructure/setUpEnvironment`
7. create a service account with project editor permissions in google cloud and name it: terraform-managed
8. generate a json key for the service account and add it to current folder
9. update terraform.tfvars
10. Run `terraform init`
11. Run `terraform plan` 
12. Run `terraform apply -auto-approve`
13. Run `cd .. && cd development`
14. copy the same json key from step x to current folder
15. update terraform.tfvars
16. Run `terraform init`
17. Run `terraform plan` 
18. Run `terraform apply -auto-approve`
19. Run `cd ..` 
20. Update the project_id in tf-serving/configmap.yaml
21. Run 
```
gcloud container clusters get-credentials infrastructure-as-code-385010-gke --zone us-central1-c && \
kubectl apply -f tf-serving/configmap.yaml && \
kubectl apply -f tf-serving/deployment.yaml && \
kubectl autoscale deployment fashion --cpu-percent=60 --min=1 --max=2 && \
kubectl apply -f tf-serving/services.yaml
```
1.  Run `kubectl get svc fashion`
2.  copy the External-IP
3.  Run `cd ../application/ml_model`
4.  open test_model_prediction.py in code editor
5.  update host variable with External-IP
6.  Run `python -u test_model_prediction.py`

## Stop services and remove infrastructure
1. cd project_directory
2. Run `cd infrastructure`
3. Run 
```
kubectl delete -f tf-serving/services.yaml && \
kubectl delete -f tf-serving/deployment.yaml && \
kubectl delete -f tf-serving/configmap.yaml 
```
4. Run `cd development`
5. Run `terraform destroy -auto-approve`
6. Run `cd ../setUpEnvironment`
7. Run `terraform destroy -auto-approve`